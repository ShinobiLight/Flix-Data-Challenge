{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3930d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_SPLIT = 0.7\n",
    "IM_WIDTH, IM_HEIGHT = 133, 225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "class DataGenerator():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def generate_split_indexes(self):\n",
    "        p = np.random.permutation(len(self.df))\n",
    "        train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT)\n",
    "        train_idx = p[:train_up_to]\n",
    "        test_idx = p[train_up_to:]\n",
    "        train_up_to = int(train_up_to * TRAIN_TEST_SPLIT)\n",
    "        train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "        \n",
    "        return train_idx, valid_idx, test_idx\n",
    "        \n",
    "    def preprocess_image(self, img_path):\n",
    "        im = Image.open(img_path)\n",
    "        im = im.resize((IM_WIDTH, IM_HEIGHT))\n",
    "        im = np.array(im) / 255.0\n",
    "        \n",
    "        return im\n",
    "        \n",
    "    \n",
    "    def generate_images(self, image_idx, is_training, batch_size=16):\n",
    "        \n",
    "        # arrays to store batched data\n",
    "        images, necks, lengths, patterns = [], [], [], []\n",
    "        while True:\n",
    "            for idx in image_idx:\n",
    "                person = self.df.iloc[idx]\n",
    "                \n",
    "                neck = person['neck']\n",
    "                length = person['sleeve_length']\n",
    "                pattern = person['pattern']\n",
    "                file = 'imgs_edge/'+person['filename']\n",
    "            \n",
    "                necks.append(to_categorical(neck))\n",
    "                patterns.append(to_categorical(pattern))\n",
    "                lengths.append(to_categorical(length))\n",
    "                \n",
    "                im = self.preprocess_image(file)\n",
    "                images.append(im)\n",
    "                \n",
    "                # yielding condition\n",
    "                if len(images) >= batch_size:\n",
    "                    yield np.array(images), [np.array(necks), np.array(lengths), np.array(patterns)]\n",
    "                    images, necks, lengths, patterns = [], [], [], []\n",
    "                    \n",
    "            if not is_training:\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d7528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleandata.csv', index_col=0)       \n",
    "for ix, fname in zip(range(len(df['filename'])), df['filename']):\n",
    "    if os.path.exists('imgs_edge/'+fname):\n",
    "        pass\n",
    "    else: \n",
    "        df = df[df.filename != fname]\n",
    "print(df.shape)\n",
    "data_generator = DataGenerator(df)\n",
    "train_idx, valid_idx, test_idx = data_generator.generate_split_indexes() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa798247",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_necks, num_lengths, num_patterns = 7, 4, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "class MultiOutputModel():\n",
    "\n",
    "    def make_default_hidden_layers(self, inputs):\n",
    "        \n",
    "        x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        return x\n",
    "    def build_neck_branch(self, inputs, num_neck):\n",
    "        \n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(num_necks)(x)\n",
    "        x = Activation(\"softmax\", name=\"neck_output\")(x)\n",
    "        return x\n",
    "    def build_length_branch(self, inputs, num_length):\n",
    "        \n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(num_lengths)(x)\n",
    "        x = Activation(\"softmax\", name=\"length_output\")(x)\n",
    "        return x\n",
    "    def build_pattern_branch(self, inputs, num_pattern):   \n",
    "        \n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(num_patterns)(x)\n",
    "        x = Activation(\"softmax\", name=\"pattern_output\")(x)\n",
    "        return x\n",
    "    def assemble_full_model(self, width, height, num_necks, num_lengths, num_patterns):\n",
    "        \n",
    "        input_shape = (height, width, 3)\n",
    "        inputs = Input(shape=input_shape)\n",
    "        neck_branch = self.build_neck_branch(inputs, num_necks)\n",
    "        length_branch = self.build_length_branch(inputs, num_lengths)\n",
    "        pattern_branch = self.build_pattern_branch(inputs, num_patterns)\n",
    "        model = Model(inputs=inputs,\n",
    "                     outputs = [neck_branch, length_branch, pattern_branch],\n",
    "                     name=\"Shape_net\")\n",
    "        return model\n",
    "    \n",
    "model = MultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT, num_necks, num_lengths, num_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81a46d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "init_lr = 1e-4\n",
    "epochs = 100\n",
    "opt = Adam(lr=init_lr, decay=init_lr / epochs)\n",
    "model.compile(optimizer=opt, \n",
    "              loss={\n",
    "                  'neck_output': 'categorical_crossentropy', \n",
    "                  'length_output': 'categorical_crossentropy', \n",
    "                  'pattern_output': 'categorical_crossentropy'},\n",
    "              loss_weights={\n",
    "                  'neck_output': 1, \n",
    "                  'length_output': 1, \n",
    "                  'pattern_output': 1},\n",
    "              metrics={\n",
    "                  'neck_output': 'accuracy', \n",
    "                  'length_output': 'accuracy',\n",
    "                  'pattern_output': 'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84bf1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "batch_size = 32\n",
    "valid_batch_size = 32\n",
    "train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\n",
    "valid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"./model_checkpoint\", monitor='val_loss')\n",
    "]\n",
    "history = model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=len(train_idx)//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd76848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "plt.clf()\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['neck_output_acc'],\n",
    "                    name='Train'))\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['val_neck_output_acc'],\n",
    "                    name='Valid'))\n",
    "fig.update_layout(height=500, \n",
    "                  width=700,\n",
    "                  title='Accuracy for neck feature',\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Accuracy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be44055",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scattergl(\n",
    "                    y=history.history['loss'],\n",
    "                    name='Train'))\n",
    "fig.add_trace(go.Scattergl(\n",
    "                    y=history.history['val_loss'],\n",
    "                    name='Valid'))\n",
    "fig.update_layout(height=500, \n",
    "                  width=700,\n",
    "                  title='Overall loss',\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c4fc10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236055a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9892f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
